{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensor Flow Low Level API.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMhFky1MY5qhxFXrgVQEEu5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amazingashis/Machine_Learning_Advanced/blob/main/Tensor_Flow_Low_Level_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML1b69-M6_RF"
      },
      "source": [
        "\n",
        "# **Introduction to Variables**\n",
        "A TensorFlow variable is the recommended way to represent shared, persistent state your program manipulates. This guide covers how to create, update, and manage instances of tf.Variable in TensorFlow.\n",
        "\n",
        "Variables are created and tracked via the tf.Variable class. A tf.Variable represents a tensor whose value can be changed by running ops on it. Specific ops allow you to read and modify the values of this tensor. Higher level libraries like tf.keras use tf.Variable to store model parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjqlBtZV7C82"
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsk-xyZo7GuF"
      },
      "source": [
        "my_tensor = tf.constant(5)\n",
        "my_variable = tf.Variable([[4,6],[5,6]])\n",
        "\n",
        "# Variables can be all kinds of types, just like tensors\n",
        "bool_variable = tf.Variable([False, False, False, True])\n",
        "complex_variable = tf.Variable([5 + 4j, 6 + 1j])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N6VsUaA9Td2"
      },
      "source": [
        "A variable looks and acts like a tensor, and, in fact, is a data structure backed by a tf.Tensor. Like tensors, they have a dtype and a shape, and can be exported to NumPy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjh-bAa69IpD",
        "outputId": "4e8ec544-c212-416c-816b-0d8c0f1a758f"
      },
      "source": [
        "print(\"Shape:\",my_variable.shape)\n",
        "print(\"Dtype\",my_variable.dtype)\n",
        "print(\"As Numpy:\",my_variable.numpy)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape: (2, 2)\n",
            "Dtype <dtype: 'int32'>\n",
            "As Numpy: <bound method BaseResourceVariable.numpy of <tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
            "array([[4, 6],\n",
            "       [5, 6]], dtype=int32)>>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR-ixGIW-r-y"
      },
      "source": [
        "\n",
        "Most tensor operations work on variables as expected, although variables cannot be reshaped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GP3VTzD97hq",
        "outputId": "4861840a-28bc-4e18-80ad-f3993c085bf0"
      },
      "source": [
        "print(\"A variable:\",my_variable)\n",
        "print(\"\\nViewed as a tensor:\", tf.convert_to_tensor(my_variable))\n",
        "print(\"\\nIndex of highest value:\", tf.argmax(my_variable))\n",
        "\n",
        "# This creates a new tensor; it does not reshape the variable.\n",
        "print(\"\\nCopying and reshaping: \", tf.reshape(my_variable, ([1,4])))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A variable: <tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
            "array([[4, 6],\n",
            "       [5, 6]], dtype=int32)>\n",
            "\n",
            "Viewed as a tensor: tf.Tensor(\n",
            "[[4 6]\n",
            " [5 6]], shape=(2, 2), dtype=int32)\n",
            "\n",
            "Index of highest value: tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
            "\n",
            "Copying and reshaping:  tf.Tensor([[4 6 5 6]], shape=(1, 4), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K7IOhEG_7Ic"
      },
      "source": [
        "As noted above, variables are backed by tensors. You can reassign the tensor using tf.Variable.assign. Calling assign does not (usually) allocate a new tensor; instead, the existing tensor's memory is reused."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvtacTj7-uk1",
        "outputId": "6c87c36d-2504-4401-cdb6-6e66cb5fc871"
      },
      "source": [
        "\n",
        "a = tf.Variable([2.0, 3.0])\n",
        "# This will keep the same dtype, float32\n",
        "a.assign([1, 2]) \n",
        "# Not allowed as it resizes the variable: \n",
        "try:\n",
        "  a.assign([1.0, 2.0, 3.0])\n",
        "except Exception as e: print(e)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes (2,) and (3,) are incompatible\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXUIKCT6A5Hd"
      },
      "source": [
        "\n",
        "If you use a variable like a tensor in operations, you will usually operate on the backing tensor.\n",
        "\n",
        "Creating new variables from existing variables duplicates the backing tensors. Two variables will not share the same memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDPMJMOhARvJ",
        "outputId": "2cefc178-4b49-4bab-ede4-cc58a8bbdd65"
      },
      "source": [
        "a = tf.Variable([2.0, 3.0])\n",
        "# Create b based on the value of a\n",
        "b = tf.Variable(a)\n",
        "a.assign([5, 6])\n",
        "\n",
        "# a and b are different\n",
        "print(a.numpy())\n",
        "print(b.numpy())\n",
        "\n",
        "# There are other versions of assign\n",
        "print(a.assign_add([2,3]).numpy())  # [7. 9.]\n",
        "print(a.assign_sub([7,9]).numpy())  # [0. 0.]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5. 6.]\n",
            "[2. 3.]\n",
            "[7. 9.]\n",
            "[0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgV_lioqJQ7S"
      },
      "source": [
        "\n",
        "# **Lifecycles, naming, and watching**\n",
        "In Python-based TensorFlow, tf.Variable instance have the same lifecycle as other Python objects. When there are no references to a variable it is automatically deallocated.\n",
        "\n",
        "Variables can also be named which can help you track and debug them. You can give two variables the same name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUcXAtuwCAl9",
        "outputId": "1d476f83-f019-4ce1-f54f-a9513bfafb81"
      },
      "source": [
        "# Create a and b; they have the same value but are backed by different tensors.\n",
        "a = tf.Variable(my_tensor, name=\"Mark\")\n",
        "# A new variable with the same name, but different value\n",
        "# Note that the scalar add is broadcast\n",
        "b = tf.Variable(my_tensor + 1, name=\"Mark\")\n",
        "\n",
        "# These are elementwise-unequal, despite having the same name\n",
        "print(a == b)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(False, shape=(), dtype=bool)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6xfTqzgJVKI"
      },
      "source": [
        "\n",
        "Variable names are preserved when saving and loading models. By default, variables in models will acquire unique variable names automatically, so you don't need to assign them yourself unless you want to.\n",
        "\n",
        "Although variables are important for differentiation, some variables will not need to be differentiated. You can turn off gradients for a variable by setting trainable to false at creation. An example of a variable that would not need gradients is a training step counter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72A-EnJUJTTK"
      },
      "source": [
        "step_counter = tf.Variable(1,trainable=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Klk0SaNjK3zC"
      },
      "source": [
        "\n",
        "# **Placing variables and tensors**\n",
        "For better performance, TensorFlow will attempt to place tensors and variables on the fastest device compatible with its dtype. This means most variables are placed on a GPU if one is available.\n",
        "\n",
        "However, we can override this. In this snippet, we can place a float tensor and a variable on the CPU, even if a GPU is available. By turning on device placement logging, we can see where the variable is placed.\n",
        "\n",
        "Note: Although manual placement works, using can be a more convenient and scalable way to optimize your computation.\n",
        "\n",
        "If you run this notebook on different backends with and without a GPU you will see different logging. Note that logging device placement must be turned on at the start of the session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IKaJE1NK06Z",
        "outputId": "f9b497ec-8091-4324-bfd4-c787adb09f35"
      },
      "source": [
        "with tf.device('CPU:0'):\n",
        "\n",
        "  # Create some tensors\n",
        "  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "  c = tf.matmul(a, b)\n",
        "\n",
        "print(c)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cAML-v6MIHM"
      },
      "source": [
        "It's possible to set the location of a variable or tensor on one device and do the computation on another device. This will introduce delay, as data needs to be copied between the devices.\n",
        "\n",
        "You might do this, however, if you had multiple GPU workers but only want one copy of the variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukUDRDOtMGpf",
        "outputId": "ace39168-cd0f-450c-a9a6-fb0b14eafe23"
      },
      "source": [
        "with tf.device('CPU:0'):\n",
        "  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "  b = tf.Variable([[1.0, 2.0, 3.0]])\n",
        "\n",
        "with tf.device('GPU:0'):\n",
        "  # Element-wise multiply\n",
        "  k = a * b\n",
        "\n",
        "print(k)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 1.  4.  9.]\n",
            " [ 4. 10. 18.]], shape=(2, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2GejaadMOnR"
      },
      "source": [
        "Note: Because tf.config.set_soft_device_placement is turned on by default, even if you run this code on a device without a GPU, it will still run and the multiplication step happen on the CPU.\n",
        "\n",
        "\n",
        "\n",
        "# Writing Low-Level TensorFlow Code\n",
        "**Learning Objectives**\n",
        "\n",
        "* Practice defining and performing basic operations on constant Tensors\n",
        "* Use Tensorflow's automatic differentiation capability\n",
        "* Learn how to train a linear regression from scratch with TensorFLow\n",
        "\n",
        "\n",
        "# Introduction\n",
        "In this notebook, we will start by reviewing the main operations on Tensors in TensorFlow and understand how to manipulate TensorFlow Variables. We explain how these are compa\n",
        "tible with python built-in list and numpy arrays.\n",
        "\n",
        "Then we will jump to the problem of training a linear regression from scratch with gradient descent. The first order of business will be to understand how to compute the gradients of a function (the loss here) with respect to some of its arguments (the model weights here). The TensorFlow construct allowing us to do that is tf.GradientTape, which we will describe.\n",
        "\n",
        "At last we will create a simple training loop to learn the weights of a 1-dim linear regression using synthetic data generated from a linear model.\n",
        "\n",
        "As a bonus exercise, we will do the same for data generated from a non linear model, forcing us to manual engineer non-linear features to improve our linear model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jMdUhF5MMFK"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwLvYCc8NDyZ"
      },
      "source": [
        "# **Operations on tensors**\n",
        "**Variables and Constants**\n",
        "Tensors in TensorFlow are either contant (tf.constant) or variables (tf.Variable). Constant values can not be changed, while variables values can be.\n",
        "\n",
        "The main difference is that instances of tf.Variable have methods allowing us to change their values while tensors constructed with tf.constant don't have these methods, and therefore their values can not be changed. When you want to change the value of a tf.Variable x use one of the following method:\n",
        "\n",
        "* x.assign(new_value)\n",
        "* x.assign_add(value_to_be_added)\n",
        "* x.assign_sub(value_to_be_subtracted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFX4ikDsMbPH",
        "outputId": "9e6a26b5-e638-4e22-d9bb-416b6d642efd"
      },
      "source": [
        "x = tf.constant([2,3,4])\n",
        "x\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 3, 4], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGElsCnvPVCe"
      },
      "source": [
        "x = tf.Variable(2.0,dtype = tf.float32,name = 'my_variable')\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUSB5p6qPhmD",
        "outputId": "3bf2f3ac-4fed-4817-9e74-99f075634778"
      },
      "source": [
        "x.assign(45.8)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=45.8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwACIiFfPpp9",
        "outputId": "fa138caa-57f0-4b35-cd21-27c151b29b48"
      },
      "source": [
        "x.assign_add(4)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=49.8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRlubyEFPxsb"
      },
      "source": [
        "# **Point wise Operators**\n",
        "Tensorflow offers similar point-wise tensor operations as numpy does:\n",
        "\n",
        "* tf.add allows to add the components of a tensor\n",
        "* tf.multiply allows us to multiply the components of a tensor\n",
        "* tf.subtract allow us to substract the components of a tensor\n",
        "* tf.math.* contains the usual math operations to be applied on the components of a tensor\n",
        "* and many more...\n",
        "Most of the standard arithmetic operations (tf.add, tf.substrac, etc.) are overloaded by the usual corresponding arithmetic symbols (+, -, etc.)\n",
        "\n",
        "Lab Task #1: Performing basic operations on Tensors\n",
        "\n",
        "* Compute the sum of the constants a and b below using tf.add and + and verify both operations produce the same values.\n",
        "* Compute the product of the constants a and b below using tf.multiply and * and verify both operations produce the same values.\n",
        "* Compute the exponential of the constant a using tf.math.exp. Note, you'll need to specify the type for this operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXSsmBjRPtd_",
        "outputId": "8316cfba-2f64-4a0b-b11f-08cd0d46f0e7"
      },
      "source": [
        "# Creates a constant tensor from a tensor-like object.\n",
        "a = tf.constant([5, 3, 8]) # TODO 1a\n",
        "b = tf.constant([3, -1, 2])\n",
        "# Using the .add() method components of a tensor will be added.\n",
        "c = tf.add(a, b)\n",
        "d = a + b\n",
        "\n",
        "# Let's output the value of `c` and `d`.\n",
        "print(\"c:\", c)\n",
        "print(\"d:\", d)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c: tf.Tensor([ 8  2 10], shape=(3,), dtype=int32)\n",
            "d: tf.Tensor([ 8  2 10], shape=(3,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDAvOVS-QIWM",
        "outputId": "435f6e75-2cb6-48f4-a407-d4dc07644e30"
      },
      "source": [
        "# Creates a constant tensor from a tensor-like object.\n",
        "a = tf.constant([5, 3, 8]) # TODO 1b\n",
        "b = tf.constant([3, -1, 2])\n",
        "# Using the .multiply() method components of a tensor will be multiplied.\n",
        "c = tf.multiply(a, b)\n",
        "d = a * b\n",
        "\n",
        "# Let's output the value of `c` and `d`.\n",
        "print(\"c:\", c)\n",
        "print(\"d:\", d)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c: tf.Tensor([15 -3 16], shape=(3,), dtype=int32)\n",
            "d: tf.Tensor([15 -3 16], shape=(3,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWAYzeDaQKn3",
        "outputId": "da16aa6d-bca0-498b-ec8c-54390ce0f7f3"
      },
      "source": [
        "# TODO 1c\n",
        "# tf.math.exp expects floats so we need to explicitly give the type\n",
        "a = tf.constant([5, 3, 8], dtype=tf.float32)\n",
        "b = tf.math.exp(a)\n",
        "\n",
        "# Let's output the value of `b`.\n",
        "print(\"b:\", b)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b: tf.Tensor([ 148.41316    20.085537 2980.958   ], shape=(3,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPmuBgm-QaHU"
      },
      "source": [
        "# **NumPy Interoperability**\n",
        "In addition to native TF tensors, tensorflow operations can take native python types and NumPy arrays as operands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adw2ZuPHQM0b"
      },
      "source": [
        "# native python list\n",
        "a_py = [1, 2] \n",
        "b_py = [3, 4]\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n56GAAKhRawx",
        "outputId": "4bf79e55-18ee-4663-ac50-b199328fe69a"
      },
      "source": [
        "# Using the .add() method components of a tensor will be added.\n",
        "tf.add(a_py, b_py)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 6], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHMNpCJ-Rd1B"
      },
      "source": [
        "# numpy arrays\n",
        "a_np = np.array([1, 2])\n",
        "b_np = np.array([3, 4])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSaoLnz7Rfc0",
        "outputId": "eec24f61-18de-45b9-f6d5-b506d54b8598"
      },
      "source": [
        "# Using the .add() method components of a tensor will be added.\n",
        "tf.add(a_np, b_np)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([4, 6])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSGJ04Q2RhUv"
      },
      "source": [
        "# native TF tensor\n",
        "a_tf = tf.constant([1, 2])\n",
        "b_tf = tf.constant([3, 4])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6DAMJMRRjHW",
        "outputId": "8bb7c981-a4d0-4850-b933-fde80914759a"
      },
      "source": [
        "\n",
        "# Using the .add() method components of a tensor will be added.\n",
        "tf.add(a_tf, b_tf)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 6], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7A0IjGaRkej"
      },
      "source": [
        "\n",
        "# Here using the .numpy() method we'll convert a `native TF tensor` to a `NumPy array`.\n",
        "a_tf.numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvyHUKvVRohk"
      },
      "source": [
        "# **Linear Regression**\n",
        "Now let's use low level tensorflow operations to implement linear regression.\n",
        "\n",
        "Later in the course you'll see abstracted ways to do this using high level TensorFlow.\n",
        "\n",
        "**Toy Dataset**\n",
        "\n",
        "We'll model the following function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb20WLm6RtVT",
        "outputId": "fab6d137-2bfa-4689-c354-54fcc906510d"
      },
      "source": [
        "X = tf.constant(range(10), dtype=tf.float32)\n",
        "Y = 2 * X + 10\n",
        "\n",
        "print(\"X:{}\".format(X))\n",
        "print(\"Y:{}\".format(Y))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X:[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
            "Y:[10. 12. 14. 16. 18. 20. 22. 24. 26. 28.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzrRVZyhSG9K",
        "outputId": "fc2ec8ce-b1f4-45fd-8bf2-7950255d2523"
      },
      "source": [
        "X_test = tf.constant(range(10, 20), dtype=tf.float32)\n",
        "Y_test = 2 * X_test + 10\n",
        "\n",
        "print(\"X_test:{}\".format(X_test))\n",
        "print(\"Y_test:{}\".format(Y_test))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_test:[10. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
            "Y_test:[30. 32. 34. 36. 38. 40. 42. 44. 46. 48.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH9fhCN4U80j"
      },
      "source": [
        "# Loss Function:\n",
        "The simplest model we can build is a model that for each value of x returns the sample mean of the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68EUfpWISNK3"
      },
      "source": [
        "y_mean = Y.numpy().mean()\n",
        "\n",
        "\n",
        "def predict_mean(X):\n",
        "    y_hat = [y_mean] * len(X)\n",
        "    return y_hat\n",
        "\n",
        "Y_hat = predict_mean(X_test)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQfFxhwdVn6d"
      },
      "source": [
        "Using mean squared error, our loss is:$$\n",
        "MSE = \\frac{1}{m}\\sum_{i=1}^{m}(\\hat{Y}_i-Y_i)^2\n",
        "$$\n",
        "\n",
        "For this simple model the loss is then:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScSOVYDOVBjZ",
        "outputId": "45959410-fbe1-4acf-a159-38d92779201c"
      },
      "source": [
        "errors = (Y_hat - Y)**2\n",
        "loss = tf.reduce_mean(errors)\n",
        "loss.numpy()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFP6b9ItV6yL"
      },
      "source": [
        "\n",
        "This values for the MSE loss above will give us a baseline to compare how a more complex model is doing.\n",
        "\n",
        "Now, if $\\hat{Y}$ represents the vector containing our model's predictions when we use a linear regression model$$\n",
        "\\hat{Y} = w_0X + w_1\n",
        "$$\n",
        "\n",
        "we can write a loss function taking as arguments the coefficients of the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxiOHlfFVtVa"
      },
      "source": [
        "\n",
        "def loss_mse(X, Y, w0, w1):\n",
        "    Y_hat = w0 * X + w1\n",
        "    errors = (Y_hat - Y)**2\n",
        "    return tf.reduce_mean(errors)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2vNNR3VWiCK"
      },
      "source": [
        "# **Gradient Function**\n",
        "To use gradient descent we need to take the partial derivatives of the loss function with respect to each of the weights. We could manually compute the derivatives, but with Tensorflow's automatic differentiation capabilities we don't have to!\n",
        "\n",
        "During gradient descent we think of the loss as a function of the parameters $w_0$ and $w_1$. Thus, we want to compute the partial derivative with respect to these variables.\n",
        "\n",
        "For that we need to wrap our loss computation within the context of tf.GradientTape instance which will record gradient information:\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "   \n",
        "    loss = # computation\n",
        "This will allow us to later compute the gradients of any tensor computed within the tf.GradientTape context with respect to instances of tf.Variable:\n",
        "\n",
        "\n",
        "    gradients = tape.gradient(loss, [w0, w1])\n",
        "\n",
        "We illustrate this procedure by computing the loss gradients with respect to the model weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irIGWROnWQ6p"
      },
      "source": [
        "# Let's define compute_gradients() procedure for computing the loss gradients with respect to the model weights:\n",
        "\n",
        "def compute_gradients(X, Y, w0, w1):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_mse(X, Y, w0, w1)\n",
        "    return tape.gradient(loss, [w0, w1])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jQPuxWpXDXy"
      },
      "source": [
        "# The Variable() constructor requires an initial value for the variable, which can be a Tensor of any type and shape.\n",
        "w0 = tf.Variable(0.0)\n",
        "w1 = tf.Variable(0.0)\n",
        "\n",
        "dw0, dw1 = compute_gradients(X, Y, w0, w1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHXmW3EFXH_r",
        "outputId": "b6249e6a-8aa4-4e91-e00f-14235fc08754"
      },
      "source": [
        "# Let's output the value of `dw0`.\n",
        "print(\"dw0:\", dw0.numpy())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dw0: -204.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj5PTb6oXKAT",
        "outputId": "ae3ba140-2511-465b-9d34-225303aa7851"
      },
      "source": [
        "\n",
        "# Let's output the value of `dw1`.\n",
        "print(\"dw1\", dw1.numpy())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dw1 -38.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1QNsISgXSyN"
      },
      "source": [
        "# **Training Loop**\n",
        "Here we have a very simple training loop that converges. Note we are ignoring best practices like batching, creating a separate test set, and random weight initialization for the sake of simplicity.\n",
        "\n",
        "Lab Task #3: Complete the for loop below to train a linear regression.\n",
        "\n",
        "* Use compute_gradients to compute dw0 and dw1.\n",
        "* Then, re-assign the value of w0 and w1 using the .assign_sub(...) method with the computed gradient values and the LEARNING_RATE.\n",
        "* Finally, for every 100th step , we'll compute and print the loss. Use the loss_mse function we created above to compute the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZd-FE4DXO6z",
        "outputId": "a6ff9088-4fbc-46e9-e761-6902eec1211b"
      },
      "source": [
        "STEPS = 1000\n",
        "LEARNING_RATE = .02\n",
        "MSG = \"STEP {step} - loss: {loss}, w0: {w0}, w1: {w1}\\n\"\n",
        "\n",
        "\n",
        "# The Variable() constructor requires an initial value for the variable, which can be a Tensor of any type and shape.\n",
        "w0 = tf.Variable(0.0)\n",
        "w1 = tf.Variable(0.0)\n",
        "\n",
        "\n",
        "for step in range(0, STEPS + 1):\n",
        "\n",
        "    dw0, dw1 = compute_gradients(X, Y, w0, w1)\n",
        "    w0.assign_sub(dw0 * LEARNING_RATE)\n",
        "    w1.assign_sub(dw1 * LEARNING_RATE)\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        loss = loss_mse(X, Y, w0, w1)\n",
        "        print(MSG.format(step=step, loss=loss, w0=w0.numpy(), w1=w1.numpy()))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STEP 0 - loss: 35.70719528198242, w0: 4.079999923706055, w1: 0.7599999904632568\n",
            "\n",
            "STEP 100 - loss: 2.6017532348632812, w0: 2.4780430793762207, w1: 7.002389907836914\n",
            "\n",
            "STEP 200 - loss: 0.26831889152526855, w0: 2.153517961502075, w1: 9.037351608276367\n",
            "\n",
            "STEP 300 - loss: 0.027671903371810913, w0: 2.0493006706237793, w1: 9.690855979919434\n",
            "\n",
            "STEP 400 - loss: 0.0028539239428937435, w0: 2.0158326625823975, w1: 9.90071964263916\n",
            "\n",
            "STEP 500 - loss: 0.0002943490108009428, w0: 2.005084753036499, w1: 9.96811580657959\n",
            "\n",
            "STEP 600 - loss: 3.0356444767676294e-05, w0: 2.0016329288482666, w1: 9.989760398864746\n",
            "\n",
            "STEP 700 - loss: 3.1322738323069643e-06, w0: 2.0005245208740234, w1: 9.996710777282715\n",
            "\n",
            "STEP 800 - loss: 3.2238213520940917e-07, w0: 2.0001683235168457, w1: 9.998944282531738\n",
            "\n",
            "STEP 900 - loss: 3.369950718479231e-08, w0: 2.000054359436035, w1: 9.999658584594727\n",
            "\n",
            "STEP 1000 - loss: 3.6101481803996194e-09, w0: 2.0000178813934326, w1: 9.99988842010498\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agWBOqLXYLqA",
        "outputId": "8212e93b-468f-4ba3-d76c-7383182321be"
      },
      "source": [
        "# Here we can compare the test loss for this linear regression to the test loss from the baseline model.\n",
        "# Its output will always be the mean of the training set:\n",
        "loss = loss_mse(X_test, Y_test, w0, w1)\n",
        "loss.numpy()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.4563633e-08"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuIUJ0sSYlPn"
      },
      "source": [
        "\n",
        "X = tf.constant(np.linspace(0, 2, 1000), dtype=tf.float32)\n",
        "Y = X * tf.exp(-X**2)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "b6LM6M20Yr40",
        "outputId": "f022b14d-b573-4a1b-d6a7-d72acd91941c"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# The .plot() is a versatile function, and will take an arbitrary number of arguments. For example, to plot x versus y.\n",
        "plt.plot(X, Y)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0877832dd8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1Mslt-RYtmP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}