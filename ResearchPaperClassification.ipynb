{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "Copy of ResearchPaperClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [conda root]",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amazingashis/Machine_Learning_Advanced/blob/main/ResearchPaperClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJJuJg4xgcg4"
      },
      "source": [
        "import pandas as pd \n",
        "import sklearn\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "\n",
        "import gensim, logging\n",
        "from gensim.models import Word2Vec\n",
        "from scipy import sparse"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxndEpZlgfDS",
        "outputId": "1c804864-d9b2-4b3c-f248-2b27a493d193"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMkFQt3Qgcg5"
      },
      "source": [
        "def loadData(filePath=\"/content/drive/MyDrive/Data/dataset.csv\"):\n",
        "    data = pd.read_csv(filePath, header=0)\n",
        "    return data[\"Title\"],data[\"Conference\"]\n",
        "\n",
        "def preProcessing(features):\n",
        "    num_titles = features.size\n",
        "    clean_wordlist = []\n",
        "    clean_titles = []\n",
        "    stops = set(stopwords.words('english'))\n",
        "    for i in range( 0, num_titles):\n",
        "        #letters_only = re.sub(\"[^a-zA-Z]\", \" \", features[i]) \n",
        "        words = features[i].lower().split()\n",
        "        words = [w.lower() for w in words if not w in stops]  \n",
        "        clean_wordlist.append(words)\n",
        "        clean_titles.append(\" \".join(words))\n",
        "    return clean_titles, clean_wordlist"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cTHuE_2gcg6"
      },
      "source": [
        "def getDTMByTFIDF(features,nfeatures):\n",
        "    tfIdf_vectorizer = TfidfVectorizer(max_features=nfeatures)\n",
        "    dtm = tfIdf_vectorizer.fit_transform(features).toarray()\n",
        "    return dtm,tfIdf_vectorizer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-eISE_zgcg7"
      },
      "source": [
        "def featuresByChiSq(features,labels,nFeature=5000):\n",
        "    chi2_model = SelectKBest(chi2,k=nFeature)\n",
        "    dtm = chi2_model.fit_transform(features,labels)\n",
        "    return dtm,chi2_model\n",
        "\n",
        "def featuresByInformationGain(features,labels):\n",
        "    treeCL = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
        "    treeCL = treeCL.fit(features,labels)\n",
        "    transformed_features = SelectFromModel(treeCL,prefit=True).transform(features)\n",
        "    return transformed_features\n",
        "\n",
        "def featuresByLSA(features,ncomponents=100):\n",
        "    svd = TruncatedSVD(n_components=ncomponents)\n",
        "    normalizer =  Normalizer(copy=False)\n",
        "    lsa = make_pipeline(svd, normalizer)\n",
        "    dtm_lsa = lsa.fit_transform(features)\n",
        "    return dtm_lsa"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "mIIn7Tf5gcg7"
      },
      "source": [
        "def makeFeatureVec(words, model, num_features):\n",
        "    feature_vec = np.zeros((num_features,),dtype=\"float32\")\n",
        "    nwords = 0.\n",
        "    index2word_set = set(model.wv.index2word)\n",
        "    for word in words:\n",
        "        if word in index2word_set: \n",
        "            nwords = nwords + 1.\n",
        "            feature_vec = np.add(feature_vec,model[word]) \n",
        "\n",
        "    feature_vec = np.divide(feature_vec,nwords)\n",
        "   \n",
        "    return feature_vec\n",
        "\n",
        "def getAvgFeatureVecs(title, model, num_features):\n",
        "    counter = 0\n",
        "    titleFeatureVecs = np.zeros((len(title), num_features),dtype=\"float32\")\n",
        "    for t in title:\n",
        "        titleFeatureVecs[counter] = makeFeatureVec(t, model,num_features)\n",
        "        counter = counter + 1\n",
        "    return titleFeatureVecs"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shv3Dugvgcg8",
        "scrolled": false
      },
      "source": [
        "def crossValidate(document_term_matrix,labels,classifier,nfold=2):\n",
        "    clf = None\n",
        "    precision = []\n",
        "    recall = []\n",
        "    fscore = []\n",
        "    \n",
        "    if classifier == \"RF\":\n",
        "        clf = RandomForestClassifier()\n",
        "    elif classifier == \"NB\":\n",
        "        clf = MultinomialNB()\n",
        "    elif classifier == \"SVM\":\n",
        "        clf = LinearSVC()\n",
        "    \n",
        "    skf = StratifiedKFold(n_splits=nfold)\n",
        "    skf.get_n_splits(document_term_matrix, labels)\n",
        "\n",
        "    for train_index, test_index in skf.split(document_term_matrix, labels):\n",
        "        X_train, X_test = document_term_matrix[train_index], document_term_matrix[test_index]\n",
        "        y_train, y_test = labels[train_index], labels[test_index]\n",
        "        model = clf.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        p,r,f,s = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
        "        precision.append(p)\n",
        "        recall.append(r)\n",
        "        fscore.append(f)\n",
        "        \n",
        "    return np.mean(precision),np.mean(recall),np.mean(fscore)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPx82OoehwkF",
        "outputId": "a73c4d27-70da-4884-c44d-7c961462f3a7"
      },
      "source": [
        "!pip install nltk\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLozk0BziNYO"
      },
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAoaYJs5ib3G",
        "outputId": "2da52174-9176-42a6-bfee-6e3369d74477"
      },
      "source": [
        "nltk.download('stopwords')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E98sVTO7gcg9"
      },
      "source": [
        "titles, labels = loadData()\n",
        "processed_titles, processed_titles_wordlist = preProcessing(titles)\n",
        "dtm,vect = getDTMByTFIDF(processed_titles,None)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg7ydAcbgcg9"
      },
      "source": [
        "chisqDtm, chisqModel = featuresByChiSq(dtm,labels,2000)\n",
        "igDtm = featuresByInformationGain(dtm,labels)\n",
        "lsaDtm = featuresByLSA(dtm,100)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xO0hNoglgcg9"
      },
      "source": [
        "num_features = 300    # Word vector dimensionality                      \n",
        "min_word_count = 1    # Minimum word count                        \n",
        "num_workers = 1       # Number of threads to run in parallel\n",
        "context = 8           # Context window size                                                                                    \n",
        "downsampling = 1e-5   # Downsample setting for frequent words\n",
        "\n",
        "word2vec_model = Word2Vec(processed_titles_wordlist, workers=num_workers, \n",
        "            size=num_features, min_count = min_word_count, \n",
        "            window = context, sample = downsampling)\n",
        "word2vec_model.init_sims(replace=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV7C3p8Ugcg-",
        "outputId": "a4babfed-064e-4e73-d464-13f6856b175f"
      },
      "source": [
        "wordVecs = getAvgFeatureVecs(processed_titles_wordlist, word2vec_model, num_features)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8QmW2IUgcg-"
      },
      "source": [
        "#Combine features from chiSq and word2Vec\n",
        "combinedFeatures = np.hstack([chisqDtm,wordVecs])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ButVl06vgcg_",
        "outputId": "b10dbdf1-54df-45e8-aecb-ee21e4662b13"
      },
      "source": [
        "precision, recall, fscore = crossValidate(chisqDtm,labels,\"SVM\",10)\n",
        "print(\"ChiSq Features: for SVM\",precision, recall, fscore)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ChiSq Features: 0.8089088432134339 0.7997641434262948 0.793880149041286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7m0VFIYgchA",
        "outputId": "51900897-34af-4bff-bd35-1d17af9b73c4"
      },
      "source": [
        "precision, recall, fscore = crossValidate(combinedFeatures,labels,\"SVM\",10)\n",
        "print (\"ChiSq Features for SVM:\",precision, recall, fscore)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ChiSq Features: 0.7965052170945573 0.787800796812749 0.7825461095083039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQvOx3OQC0Gz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2826908b-fce4-4741-90f0-ed093ed82bec"
      },
      "source": [
        "precision, recall, fscore = crossValidate(igDtm,labels,\"SVM\",10)\n",
        "print (\"Features By InformationGain for SVM:\",precision, recall, fscore)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "featuresByInformationGain: 0.7365104399728638 0.7347776892430279 0.727798035725409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh4XT1JmV1a5",
        "outputId": "88a3e09d-71eb-445a-82d9-420a13c941e7"
      },
      "source": [
        "precision, recall, fscore = crossValidate(lsaDtm,labels,\"SVM\",10)\n",
        "print (\"Features By LSA for SVM\",precision, recall, fscore)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features By LSA 0.7367948984107847 0.7371314741035857 0.7338410722101127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs54p8KeWGmD",
        "outputId": "f9e8f207-9eff-4e81-efa6-efab9db6edef"
      },
      "source": [
        "precision, recall, fscore = crossValidate(lsaDtm,labels,\"RF\",10)\n",
        "print (\"Features By LSA for Random Forest\",precision, recall, fscore)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features By LSA for Random Forest 0.7006823664830917 0.6996302788844622 0.6922297375990426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G4qp-GkWUk2",
        "outputId": "4ca26dc4-53b6-4801-cb70-2f23141635d5"
      },
      "source": [
        "precision, recall, fscore = crossValidate(igDtm,labels,\"RF\",10)\n",
        "print (\"Features By InformationGain for Random Forest:\",precision, recall, fscore)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features By InformationGain for Random Forest: 0.7304839945249499 0.7176 0.71848275016834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDrL7lMHWYuw",
        "outputId": "c17bdad8-a7eb-4d1b-bae6-0ebb30094d9b"
      },
      "source": [
        "precision, recall, fscore = crossValidate(chisqDtm,labels,\"RF\",10)\n",
        "print(\"ChiSq Features: for  Random Forest\",precision, recall, fscore)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ChiSq Features: for  Random Forest 0.7344008003856545 0.7008509960159363 0.6883783967140573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chzDmLNYWflG",
        "outputId": "40f2b404-57ce-44b8-9b3c-0195021d1ff1"
      },
      "source": [
        "precision, recall, fscore = crossValidate(igDtm,labels,\"NB\",10)\n",
        "print (\"Features By InformationGain for Nave Bayes:\",precision, recall, fscore)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features By InformationGain for Nave Bayes: 0.7128171358913977 0.6234645418326694 0.5898090189345938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4r2dWICWyS8",
        "outputId": "5bf8791f-d04a-4414-cfbe-e7297d2efcdd"
      },
      "source": [
        "precision, recall, fscore = crossValidate(chisqDtm,labels,\"NB\",10)\n",
        "print(\"ChiSq Features: for  Nave Bayes\",precision, recall, fscore)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ChiSq Features: for  Nave Bayes 0.7707542103728363 0.7024302788844621 0.6783470032212775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mI5p3-3XDrj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}